{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08ef6055-8846-4f14-960b-e7ada0ad3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: PubMed()\n",
      "Number of nodes: 19717\n",
      "Number of edges: 88648\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "Train Mask: 9858 nodes\n",
      "Test Mask: 1000 nodes\n",
      "Target Dataset Nodes: 9858\n",
      "Shadow Dataset Nodes: 9859\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42  # You can change this number, but it should be the same across all runs\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Load the PubMed dataset\n",
    "dataset = Planetoid(root='/tmp/PubMed', name='PubMed')\n",
    "data = dataset[0]\n",
    "\n",
    "# Split nodes into target and shadow sets\n",
    "nodes = np.arange(data.num_nodes)\n",
    "target_nodes, shadow_nodes = train_test_split(nodes, test_size=0.5, random_state=seed)\n",
    "\n",
    "# Create training masks\n",
    "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "data.train_mask[target_nodes] = True\n",
    "\n",
    "shadow_data = data.clone()\n",
    "shadow_data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "shadow_data.train_mask[shadow_nodes] = True\n",
    "\n",
    "# Inspect dataset\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Number of features: {data.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Train Mask: {data.train_mask.sum()} nodes\")\n",
    "print(f\"Test Mask: {data.test_mask.sum()} nodes\")\n",
    "print(f\"Target Dataset Nodes: {len(target_nodes)}\")\n",
    "print(f\"Shadow Dataset Nodes: {len(shadow_nodes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d8fb497-ca5d-442a-900a-c7f3275292d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 128)\n",
    "        self.conv2 = GCNConv(128, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize models\n",
    "target_model = GCN(dataset.num_node_features, dataset.num_classes)\n",
    "shadow_model = GCN(dataset.num_node_features, dataset.num_classes)\n",
    "\n",
    "print(\"Models initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae4aa031-cdb2-4044-b7df-88b817c6d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Target Model...\n",
      "Epoch 50/200, Loss: 0.8608\n",
      "Epoch 100/200, Loss: 0.6319\n",
      "Epoch 150/200, Loss: 0.5199\n",
      "Epoch 200/200, Loss: 0.4680\n",
      "Training Shadow Model...\n",
      "Epoch 50/200, Loss: 0.8688\n",
      "Epoch 100/200, Loss: 0.6268\n",
      "Epoch 150/200, Loss: 0.5103\n",
      "Epoch 200/200, Loss: 0.4593\n",
      "Testing Target Model...\n",
      "Test Accuracy: 0.8630\n",
      "Testing Shadow Model...\n",
      "Test Accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "\n",
    "def train_model(model, data, optimizer, num_epochs=200):\n",
    "    model.train()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Train models\n",
    "target_optimizer = optim.Adam(target_model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "\n",
    "# Define accuracy calculation\n",
    "def accuracy(output, labels, mask):\n",
    "    # Get the predicted class for each node\n",
    "    _, pred = output.max(dim=1)\n",
    "    \n",
    "    # Apply the mask to get the relevant labels\n",
    "    correct = (pred[mask] == labels[mask]).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    \n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "print(\"Training Target Model...\")\n",
    "train_model(target_model, data, target_optimizer)\n",
    "\n",
    "print(\"Training Shadow Model...\")\n",
    "train_model(shadow_model, shadow_data, shadow_optimizer)\n",
    "\n",
    "def test_model(model, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        output = model(data)\n",
    "        test_acc = accuracy(output, data.y, data.test_mask)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(\"Testing Target Model...\")\n",
    "test_model(target_model, data)\n",
    "\n",
    "print(\"Testing Shadow Model...\")\n",
    "test_model(shadow_model, shadow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa75c2d8-c7e7-4770-be52-7346a64bd9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior-only attack implemented.\n"
     ]
    }
   ],
   "source": [
    "def posterior_attack(model, data, node_u, node_v, hops=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embedding_u = model.conv1(data.x, data.edge_index)[node_u]\n",
    "        embedding_v = model.conv1(data.x, data.edge_index)[node_v]\n",
    "\n",
    "        if hops >= 1:\n",
    "            neighbors_u = data.edge_index[1][data.edge_index[0] == node_u]\n",
    "            neighbors_v = data.edge_index[1][data.edge_index[0] == node_v]\n",
    "            embedding_u += torch.mean(model.conv1(data.x, data.edge_index)[neighbors_u], dim=0)\n",
    "            embedding_v += torch.mean(model.conv1(data.x, data.edge_index)[neighbors_v], dim=0)\n",
    "#working fine here\n",
    "\n",
    "        if hops == 2:\n",
    "            two_hop_neighbors_u = data.edge_index[1][torch.isin(data.edge_index[0], neighbors_u)]\n",
    "            two_hop_neighbors_v = data.edge_index[1][torch.isin(data.edge_index[0], neighbors_v)]\n",
    "            embedding_u += torch.mean(model.conv1(data.x, data.edge_index)[two_hop_neighbors_u], dim=0)\n",
    "            embedding_v += torch.mean(model.conv1(data.x, data.edge_index)[two_hop_neighbors_v], dim=0)\n",
    "\n",
    "        similarity = torch.dot(embedding_u, embedding_v)\n",
    "    return similarity.item()\n",
    "\n",
    "print(\"Posterior-only attack implemented.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83024604-c75e-43f3-93cb-61bacef0770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50 node pairs.\n",
      "Generated node pairs as: [(14651, 18670), (8131, 3136), (5839, 735), (11637, 7932), (9723, 7089), (14195, 6412), (529, 3957), (8763, 2862), (12811, 15824), (18908, 2408), (16003, 17111), (8296, 12066), (18661, 905), (6818, 869), (530, 2591), (13358, 6273), (2385, 6697), (8449, 14618), (18580, 17471), (5270, 767), (19125, 16261), (4632, 5661), (6475, 18786), (5223, 15813), (1581, 12015), (7223, 14719), (19309, 9115), (212, 5231), (13848, 11149), (9105, 5094), (7055, 11029), (3349, 3039), (12449, 3169), (11763, 11270), (8667, 1423), (15054, 17571), (4090, 12403), (2582, 18089), (9606, 11850), (18918, 6300), (2279, 1501), (7467, 9482), (2614, 7628), (3309, 12455), (9108, 14857), (11954, 5329), (12130, 11641), (6865, 8748), (2339, 5607), (17502, 8021)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_node_pairs(data, num_pairs=50):\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    num_nodes = data.num_nodes\n",
    "\n",
    "    # Positive pairs (linked nodes)\n",
    "    positive_pairs = list(zip(edge_index[0], edge_index[1]))\n",
    "    positive_pairs = random.sample(positive_pairs, min(len(positive_pairs), num_pairs // 2))\n",
    "\n",
    "    # Negative pairs (unlinked nodes)\n",
    "    negative_pairs = []\n",
    "    existing_pairs = set(positive_pairs)\n",
    "    while len(negative_pairs) < num_pairs // 2:\n",
    "        u, v = random.randint(0, num_nodes - 1), random.randint(0, num_nodes - 1)\n",
    "        if u != v and (u, v) not in existing_pairs and (v, u) not in existing_pairs:\n",
    "            negative_pairs.append((u, v))\n",
    "\n",
    "    node_pairs = positive_pairs + negative_pairs\n",
    "    labels = [1] * len(positive_pairs) + [0] * len(negative_pairs)\n",
    "    return node_pairs, labels\n",
    "\n",
    "node_pairs, true_labels = generate_node_pairs(data, num_pairs=50)\n",
    "print(f\"Generated {len(node_pairs)} node pairs.\")\n",
    "print(\"Generated node pairs as:\", node_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38a5c301-856b-4b4b-af62-3ace8faa3cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-hop Posterior-Only Attack AUC: 0.9520\n",
      "1-hop Posterior-Only Attack AUC: 0.8208\n",
      "2-hop Posterior-Only Attack AUC: 0.8736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for hops in range(3):  # 0-hop, 1-hop, 2-hop\n",
    "    posterior_scores = [posterior_attack(target_model, data, u, v, hops=hops) for u, v in node_pairs]\n",
    "    auc = roc_auc_score(true_labels, posterior_scores)\n",
    "    print(f\"{hops}-hop Posterior-Only Attack AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5c5dc42-b900-479c-afda-93307d0e0916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_operations(features_u, features_v):\n",
    "    \"\"\"Construct symmetric features using pairwise operations.\"\"\"\n",
    "    hadamard = features_u * features_v\n",
    "    average = (features_u + features_v) / 2\n",
    "    weighted_l1 = torch.abs(features_u - features_v)\n",
    "    weighted_l2 = (features_u - features_v) ** 2\n",
    "    return torch.cat([hadamard, average, weighted_l1, weighted_l2], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ce424e5-a4cc-410d-82e2-1f47750d1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_graph_features(data, node_u, node_v):\n",
    "    neighbors_u = set(data.edge_index[1][data.edge_index[0] == node_u].cpu().numpy())\n",
    "    neighbors_v = set(data.edge_index[1][data.edge_index[0] == node_v].cpu().numpy())\n",
    "    common_neighbors = len(neighbors_u.intersection(neighbors_v))\n",
    "    union = len(neighbors_u.union(neighbors_v))\n",
    "    jaccard = common_neighbors / union if union > 0 else 0.0\n",
    "    return torch.tensor([common_neighbors, jaccard], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79453946-4437-48a9-a94b-42f578649e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_attack(model, data, node_u, node_v, use_attributes=True, use_graph_features=True, hops=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Posterior embeddings\n",
    "        embedding_u = model.conv1(data.x, data.edge_index)[node_u]\n",
    "        embedding_v = model.conv1(data.x, data.edge_index)[node_v]\n",
    "        \n",
    "        if hops >= 1:\n",
    "            neighbors_u = data.edge_index[1][data.edge_index[0] == node_u]\n",
    "            neighbors_v = data.edge_index[1][data.edge_index[0] == node_v]\n",
    "            embedding_u += torch.mean(model.conv1(data.x, data.edge_index)[neighbors_u], dim=0)\n",
    "            embedding_v += torch.mean(model.conv1(data.x, data.edge_index)[neighbors_v], dim=0)\n",
    "\n",
    "        # Node attributes\n",
    "        attribute_features = torch.zeros(0)\n",
    "        if use_attributes:\n",
    "            attribute_features = pairwise_operations(data.x[node_u], data.x[node_v])\n",
    "\n",
    "        # Graph features\n",
    "        graph_features = torch.zeros(0)\n",
    "        if use_graph_features:\n",
    "            graph_features = compute_graph_features(data, node_u, node_v)\n",
    "\n",
    "        # Combine features\n",
    "        combined_features = torch.cat([embedding_u, embedding_v, attribute_features, graph_features])\n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a91371d8-48c3-4912-8292-2cc13f04b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Combined Attacks...\n",
      "0-hop Combined Attack (Attributes ): AUC = 0.9440\n",
      "0-hop Combined Attack ( Graph Features): AUC = 0.9536\n",
      "0-hop Combined Attack (Attributes Graph Features): AUC = 0.9952\n",
      "1-hop Combined Attack (Attributes ): AUC = 0.8544\n",
      "1-hop Combined Attack ( Graph Features): AUC = 0.8448\n",
      "1-hop Combined Attack (Attributes Graph Features): AUC = 0.9152\n",
      "2-hop Combined Attack (Attributes ): AUC = 0.8544\n",
      "2-hop Combined Attack ( Graph Features): AUC = 0.8448\n",
      "2-hop Combined Attack (Attributes Graph Features): AUC = 0.9152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Prepare features and labels\n",
    "def prepare_features_and_labels(node_pairs, true_labels, model, data, use_attributes, use_graph_features, hops):\n",
    "    features = [combined_attack(model, data, u, v, use_attributes, use_graph_features, hops).numpy() for u, v in node_pairs]\n",
    "    return np.array(features), np.array(true_labels)\n",
    "\n",
    "# Train and evaluate combined attacks\n",
    "def evaluate_combined_attack(use_attributes, use_graph_features, hops):\n",
    "    X, y = prepare_features_and_labels(node_pairs, true_labels, target_model, data, use_attributes, use_graph_features, hops)\n",
    "    clf = LogisticRegression(max_iter=1000).fit(X, y)\n",
    "    y_pred = clf.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, y_pred)\n",
    "    return auc\n",
    "\n",
    "print(\"Evaluating Combined Attacks...\")\n",
    "for hops in range(3):\n",
    "    for use_attributes, use_graph_features in [(True, False), (False, True), (True, True)]:\n",
    "        auc = evaluate_combined_attack(use_attributes, use_graph_features, hops)\n",
    "        attributes = \"Attributes\" if use_attributes else \"\"\n",
    "        graph = \"Graph Features\" if use_graph_features else \"\"\n",
    "        print(f\"{hops}-hop Combined Attack ({attributes} {graph}): AUC = {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50a9fc0e-3385-4139-b2e2-1bb9c1b1b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Neighbors Baseline AUC: 0.6200\n",
      "Jaccard Coefficient Baseline AUC: 0.6200\n"
     ]
    }
   ],
   "source": [
    "baseline_common = [compute_graph_features(data, u, v)[0].item() for u, v in node_pairs]\n",
    "auc_common = roc_auc_score(true_labels, baseline_common)\n",
    "\n",
    "baseline_jaccard = [compute_graph_features(data, u, v)[1].item() for u, v in node_pairs]\n",
    "auc_jaccard = roc_auc_score(true_labels, baseline_jaccard)\n",
    "\n",
    "print(f\"Common Neighbors Baseline AUC: {auc_common:.4f}\")\n",
    "print(f\"Jaccard Coefficient Baseline AUC: {auc_jaccard:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e91ba23-e570-4ac1-b126-44a791caab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-Only Defense AUC: 0.7800\n"
     ]
    }
   ],
   "source": [
    "def label_only_defense(model, data, node_pairs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = torch.argmax(model(data), dim=1)\n",
    "        scores = [1 if predictions[u] == predictions[v] else 0 for u, v in node_pairs]\n",
    "    return scores\n",
    "\n",
    "label_defense_scores = label_only_defense(target_model, data, node_pairs)\n",
    "auc_label_defense = roc_auc_score(true_labels, label_defense_scores)\n",
    "print(f\"Label-Only Defense AUC: {auc_label_defense:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "baa9eae2-761c-4e68-be30-17258f3c9fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-GCN defense applied.\n"
     ]
    }
   ],
   "source": [
    "def dp_gcn_defense(model, data, epsilon=1.0):\n",
    "    noise = torch.randn_like(data.x) * epsilon\n",
    "    perturbed_data = data.clone()\n",
    "    perturbed_data.x += noise\n",
    "    return model(perturbed_data)\n",
    "\n",
    "perturbed_output = dp_gcn_defense(target_model, data, epsilon=1.0)\n",
    "print(\"DP-GCN defense applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a2b30-582c-42be-abce-342dcfa20e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
